{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b268f3-339b-4436-898e-01b813d9693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data_Loader.ipynb\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Import from our main module\n",
    "%run config.ipynb # import config\n",
    "from Accessibility_Checker import (\n",
    "    REPORTS_DIR, \n",
    "    AccessibilityIssue, \n",
    "    normalize_url, \n",
    "    translate_accessibility_issue,\n",
    "    determine_severity,\n",
    "    terminology\n",
    ")\n",
    "\n",
    "def load_data(url=url_to_check): # changed to default to config URL\n",
    "    \"\"\"\n",
    "    Load accessibility data for a given URL from all available reports.\n",
    "    \n",
    "    Args:\n",
    "        url: URL of the website that was tested\n",
    "        \n",
    "    Returns:\n",
    "        dict: Consolidated data from all reports\n",
    "    \"\"\"\n",
    "    clean_url = normalize_url(url)\n",
    "    data = {\n",
    "        \"url\": url,\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"issues\": []\n",
    "    }\n",
    "    \n",
    "    # Track unique issues to prevent duplicates\n",
    "    unique_issues = set()\n",
    "    \n",
    "    try:\n",
    "        # Load data from various report files - using all formats of URL\n",
    "        report_types = [\n",
    "            (\"tab_order\", f\"tab_order_{clean_url}_*.json\"),\n",
    "            (\"tab_order\", f\"tab_order_{url.replace('https://', '').replace('http://', '')}_*.json\"),\n",
    "            (\"missing_focusable\", f\"missing_focusable_{clean_url}_*.json\"),\n",
    "            (\"missing_focusable\", f\"missing_focusable_{url.replace('https://', '').replace('http://', '')}_*.json\"),\n",
    "            (\"comprehensive\", f\"comprehensive_{clean_url}_*.json\"),\n",
    "            (\"comprehensive\", f\"comprehensive_{url.replace('https://', '').replace('http://', '')}_*.json\")\n",
    "        ]\n",
    "        \n",
    "        found_data = False\n",
    "        \n",
    "        for report_type, pattern in report_types:\n",
    "            full_pattern = str(REPORTS_DIR / pattern)\n",
    "            files = glob.glob(full_pattern)\n",
    "            \n",
    "            if files:\n",
    "                latest_file = max(files, key=lambda p: os.path.getmtime(p))\n",
    "                print(f\"Loading {report_type} data from: {os.path.basename(latest_file)}\")\n",
    "                \n",
    "                with open(latest_file, 'r') as f:\n",
    "                    report_data = json.load(f)\n",
    "                    \n",
    "                    # Define issue_sources based on report type\n",
    "                    issue_sources = {}\n",
    "                    \n",
    "                    if report_type == \"tab_order\":\n",
    "                        issue_sources[\"Tab Order\"] = report_data.get(\"tab_order_issues\", [])\n",
    "                    elif report_type == \"missing_focusable\":\n",
    "                        issue_sources[\"Missing Focusable\"] = report_data.get(\"missing_focusable_issues\", [])\n",
    "                    elif report_type == \"comprehensive\":\n",
    "                        issue_sources = {\n",
    "                            \"Tab Order\": report_data.get(\"tab_order_issues\", []),\n",
    "                            \"Missing Focusable\": report_data.get(\"missing_focusable_issues\", []),\n",
    "                            \"ARIA\": report_data.get(\"aria_issues\", []),\n",
    "                            \"Keyboard\": report_data.get(\"keyboard_issues\", [])\n",
    "                        }\n",
    "                    \n",
    "                    for category, issues in issue_sources.items():\n",
    "                        if not issues:\n",
    "                            continue\n",
    "                            \n",
    "                        for issue_text in issues:\n",
    "                            found_data = True\n",
    "                            \n",
    "                            # Handle different data formats\n",
    "                            if isinstance(issue_text, dict):\n",
    "                                issue_desc = issue_text.get('issue', str(issue_text))\n",
    "                            else:\n",
    "                                issue_desc = str(issue_text)\n",
    "                            \n",
    "                            # Create a unique identifier for this issue\n",
    "                            issue_hash = hashlib.md5(f\"{category}:{issue_desc}\".encode()).hexdigest()\n",
    "                            \n",
    "                            # Skip if we've already processed this issue\n",
    "                            if issue_hash in unique_issues:\n",
    "                                continue\n",
    "                            unique_issues.add(issue_hash)\n",
    "                            \n",
    "                            # Translate the issue to a more descriptive format\n",
    "                            translated_issue = translate_accessibility_issue(issue_desc, category, terminology)\n",
    "                            \n",
    "                            severity = determine_severity(translated_issue['description'])\n",
    "                            accessibility_issue = AccessibilityIssue(\n",
    "                                description=translated_issue['description'],\n",
    "                                category=category,\n",
    "                                severity=severity\n",
    "                            )\n",
    "                            \n",
    "                            # Add additional metadata to the issue\n",
    "                            accessibility_issue.original_text = translated_issue['original']\n",
    "                            accessibility_issue.impact = translated_issue['impact']\n",
    "                            accessibility_issue.recommendation = translated_issue['recommendation']\n",
    "                            \n",
    "                            data[\"issues\"].append(accessibility_issue)\n",
    "        \n",
    "        if not found_data:\n",
    "            print(f\"⚠️ Warning: No accessibility reports found for {url}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading data: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    print(f\"✅ Loaded {len(data['issues'])} unique accessibility issues from reports\")\n",
    "    return data\n",
    "\n",
    "def count_issues_by_category(data):\n",
    "    \"\"\"Count issues by category and severity\"\"\"\n",
    "    counts = {\n",
    "        'by_category': {},\n",
    "        'by_severity': {\n",
    "            'critical': 0,\n",
    "            'high': 0,\n",
    "            'medium': 0,\n",
    "            'low': 0\n",
    "        },\n",
    "        'total': len(data['issues'])\n",
    "    }\n",
    "    \n",
    "    for issue in data['issues']:\n",
    "        # Count by category\n",
    "        if issue.category not in counts['by_category']:\n",
    "            counts['by_category'][issue.category] = 0\n",
    "        counts['by_category'][issue.category] += 1\n",
    "        \n",
    "        # Count by severity\n",
    "        counts['by_severity'][issue.severity] += 1\n",
    "    \n",
    "    return counts\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    test_url = url_to_check  # Replace with your target website\n",
    "\n",
    "    print(f\"Testing data loader with URL: {test_url}\")\n",
    "    data = load_data() # removed the need to include the url\n",
    "    \n",
    "    if data[\"issues\"]:\n",
    "        counts = count_issues_by_category(data)\n",
    "        print(\"\\nIssue Counts by Category:\")\n",
    "        for category, count in counts['by_category'].items():\n",
    "            print(f\"- {category}: {count}\")\n",
    "        \n",
    "        print(\"\\nIssue Counts by Severity:\")\n",
    "        for severity, count in counts['by_severity'].items():\n",
    "            print(f\"- {severity.capitalize()}: {count}\")\n",
    "    else:\n",
    "        print(\"No issues found in any reports.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
